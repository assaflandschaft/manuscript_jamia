# PRISMA Literature Screening using GPT


## Summary


## Structure of the repository

The repository is structured in three main directories corresponding to the major data processing parts in our work: **Data Scraping**, **Screening** and **Full Text Extraction**. See below for a detailed structural and functonal breakdown of each directory.

```bash
├── Data Scraping
│   ├── google_scholar_scraper.ipynb
│   └── google_scholar_patient_trial_matching_data.csv
│
├── Screening
│   ├── results
│   │   ├── Screening_reviewer_1.xlsx
│   │   ├── Screening_reviewer_2.xlsx
│   │   ├── Screening_reviewer_GPT4.xlsx
│   │   └── Screening_resolution.xlsx
│   ├── Articles_for_screening.xlsx
│   ├── screening_parameter_extraction.ipynb
│   └── screening_agreement_calculation.ipynb
│
└── Full Text Extraction
    ├── results
    │   ├── FullText_reviewer_1.xlsx
    │   ├── FullText_reviewer_GPT4.xlsx
    │   └── FullText_resolution.xlsx
    ├── FullTextArticles
    │   ├── article_1.pdf
    │   ├── article_2.pdf
    │   └── ...
    ├── chroma_db
    │   └── ...
    ├── Articles_for_extraction.xlsx
    ├── fulltext_parameter_extraction.ipynb
    ├── fulltext_agreement_calculation.ipynb
    └── pipeline_diagram.jpg
```

### Data Scraping

```bash
├── google_scholar_scraper.ipynb
└── google_scholar_patient_trial_matching_data.csv
```
The data scraping directory contains two files, a python script that was used to scrape Google Scholar for responses to the query "patient trial matching" and a .csv file that contains the output of the 1000 scraped articles (ranks, titles, partial abstracts, corresponding hyperlinks).

The .csv file was used as a reference for manual screening. The full text of the abstracts of the first 300 search results was manually acquired. Human reviewers screened the abstracts for the use of AI/ML and NLP, in rank order, until hitting the "screening saturation" threshold (see main article for details). The articles that passed this initial screening, were complied into `Articles_for_screening.xlsx` in the **Screening** directory.


### Screening

```bash
├── results
│   ├── Screening_reviewer_1.xlsx
│   ├── Screening_reviewer_2.xlsx
│   ├── Screening_reviewer_GPT4.xlsx
│   └── Screening_resolution.xlsx
├── Articles_for_screening.xlsx
├── screening_parameter_extraction.ipynb
└── screening_agreement_calculation.ipynb
```

The screening directory has four main components:

1. `Articles_for_screening.xlsx`, a collection of the 102 articles that were manually screened before hitting the screening saturation threshold and were to undergo GPT4 screening.

2. `screening_parameter_extraction.ipynb`, a python notebook that uses GPT4 to screen the abstracts of each article from `Articles_for_screening.xlsx` for AI/ML and NLP use and saves the extracted parameters in `results/Screening_reviewer_GPT4.xlsx`

3. the `results` directory that contains

    - the screening results for each human reviewer (manually completed),
    - the screening results for GPT (generated by `screening_parameter_extraction.ipynb`),
    - the resolution values (manually obtained by aggregating answers from human reviewers and GPT and resolving conflicts where needed)

    Each excel file in `results` has a format similar to that of `Articles_for_screening.xlsx`, with columns added at the end for the **AI/ML** and **NLP** parameters. `Screening_reviewer_GPT4.xlsx` has additional columns referencing the source text backing up the values for the extracted parameters. These were used for manual conflict resolution only.

4. `screening_agreement_calculation.ipynb`, a python notebook that uses the extracted parameters from the `results` directory to calculate agreement between each pair of reviewers.



### Full Text Extraction

```bash
├── results
│   ├── FullText_reviewer_1.xlsx
│   ├── FullText_reviewer_GPT4.xlsx
│   └── FullText_resolution.xlsx
├── FullTextArticles
│   ├── article_1.pdf
│   ├── article_2.pdf
│   └── ...
├── chroma_db
│   └── ...
├── Articles_for_extraction.xlsx
├── fulltext_parameter_extraction.ipynb
├── fulltext_agreement_calculation.ipynb
└── pipeline_diagram.jpg
```

The full text extraction directory has a structure somewhat similar to the screening directory. It contains equivalents to each of the four main components from **Screening**:

1. `Articles_for_extraction.xlsx`, an excell file containing data of the 23 articles that were to undergo full text parameter extraction.

    This file is similar to `Articles_for_screening.xlsx`, but contains only the articles for which the resolution values in `Screening` confirmed that the work in the article uses BOTH **AI/ML** and **NLP**.

2. `fulltext_parameter_extraction.ipynb`, a python notebook that uses GPT4 to extract our parametrs of interest by employing the RAG methodology, as described in the article. The outputs of the notebook are saved in `results/FullText_reviewer_GPT4.xlsx`.

    The notebook references information from `FullTextArticles` and writes intermediary results to `chroma_db`. Please reference points `5.` and `6.` below.

3. the `results` directory that contains

    - the screening results for the human reviewer (manually completed),
    - the screening results for GPT (generated by `fulltext_parameter_extraction.ipynb`),
    - the resolution values (manually obtained by aggregating answers and resolving conflicts between the human reviewer and GPT)

4. `fulltret_agreement_calculation.ipynb`, a python notebook that uses the extracted parameters from the `results` directory to calculate agreement between the human reviewer and GPT, as well as the reviewers and resolution values.


Unlike **Screening**, the **Full Text Extraction** directory contains two additional directories:

5. `FullTextArticles`, a collection of PDF files of the processed articles.

    Due to distribution licensing, we cannot publish the PDF files in the repository. There were 19 files in this directory named according to the **FullText** column in `Articles_for_extraction.xlsx`. Please note that for 4 articles we were unable to get the full text and the abstracts were used for the parameter extraction. These files have "Meeting Abstract" entered into the **FullText** column in `Articles_for_extraction.xlsx`. `fulltext_parameter_extraction.ipynb` goes in details on how we differentiate between PDFs and abstracts.

6. `chroma_db`, a directory that serves as the Vector Storage for the embeddings generated by `fulltext_parameter_extraction.ipynb`.

    Currently the directory is empty, but would be filled by executing the parameter extraction. Please refer to the article and the `fulltext_parameter_extraction.ipynb` for more details on the Vector Storage.



